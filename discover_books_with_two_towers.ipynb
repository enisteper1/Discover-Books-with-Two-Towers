{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Preprocessing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pprint\n",
    "\n",
    "from typing import Dict, Text\n",
    "import tensorflow as tf\n",
    "import tensorflow_recommenders as tfrs\n",
    "import hnswlib\n",
    "\n",
    "# min rating to consider\n",
    "min_rating = 8\n",
    "# top k popular books\n",
    "top_k_popular_books = 10_000\n",
    "\n",
    "# parameters\n",
    "output_dimension = 64\n",
    "batch_size = 256\n",
    "learning_rate = 0.1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/66/b29gfxwj3tb43t74fmwm28nmrsc95x/T/ipykernel_31254/2153888385.py:2: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  books = pd.read_csv(\"dataset/Books.csv\")\n"
     ]
    }
   ],
   "source": [
    "# Datasets\n",
    "books = pd.read_csv(\"dataset/Books.csv\")\n",
    "\n",
    "ratings = pd.read_csv(\"dataset/Ratings.csv\")\n",
    "\n",
    "users = pd.read_csv(\"dataset/Users.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Users: 32188\n",
      "Number of Books: 10000\n",
      "Number of Ratings: 109041\n"
     ]
    }
   ],
   "source": [
    "# Visualization and Type Standardization\n",
    "users[\"User-ID\"] = users[\"User-ID\"].apply(lambda x: f\"user_{x}\")\n",
    "\n",
    "# Filter out books with missing or corrupted information\n",
    "books[\"ISBN\"] = books[\"ISBN\"].apply(lambda x: f\"book_{x}\")\n",
    "books.drop([\"Image-URL-S\", \"Image-URL-M\", \"Image-URL-L\"], axis=1, inplace=True)\n",
    "books.dropna(inplace=True)\n",
    "\n",
    "def clean_year(year):\n",
    "    try:\n",
    "        return int(year)\n",
    "    except ValueError:\n",
    "        return -1\n",
    "\n",
    "books['Year-Of-Publication'] = books['Year-Of-Publication'].apply(clean_year)\n",
    "books = books[books['Year-Of-Publication'] != -1].reset_index(drop=True)\n",
    "\n",
    "\n",
    "ratings[\"ISBN\"] = ratings[\"ISBN\"].apply(lambda x: f\"book_{x}\")\n",
    "ratings[\"User-ID\"] = ratings[\"User-ID\"].apply(lambda x: f\"user_{x}\")\n",
    "ratings[\"Book-Rating\"] = ratings[\"Book-Rating\"].apply(lambda x: float(x))\n",
    "ratings = ratings[ratings.ISBN.isin(books['ISBN'].unique())]\n",
    "# Filtering products for simplicity\n",
    "# Only consider high ratings\n",
    "ratings = ratings[ratings[\"Book-Rating\"] >= 8]\n",
    "# Get top 10k products\n",
    "popular_books = ratings.groupby('ISBN')['User-ID'].count().sort_values(ascending=False)[:10_000].index.tolist()\n",
    "ratings = ratings[ratings.ISBN.isin(popular_books)]\n",
    "\n",
    "# Consider user & book that has rating in ratings dataset\n",
    "books = books[books.ISBN.isin(ratings['ISBN'].unique())]\n",
    "users = users[users['User-ID'].isin(ratings['User-ID'].unique())]\n",
    "print(f\"Number of Users: {users['User-ID'].nunique()}\")\n",
    "print(f\"Number of Books: {books['ISBN'].nunique()}\")\n",
    "print(f\"Number of Ratings: {ratings.shape[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ISBN</th>\n",
       "      <th>Book-Title</th>\n",
       "      <th>Book-Author</th>\n",
       "      <th>Year-Of-Publication</th>\n",
       "      <th>Publisher</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>book_0002005018</td>\n",
       "      <td>Clara Callan</td>\n",
       "      <td>Richard Bruce Wright</td>\n",
       "      <td>2001</td>\n",
       "      <td>HarperFlamingo Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>book_0374157065</td>\n",
       "      <td>Flu: The Story of the Great Influenza Pandemic...</td>\n",
       "      <td>Gina Bari Kolata</td>\n",
       "      <td>1999</td>\n",
       "      <td>Farrar Straus Giroux</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>book_0399135782</td>\n",
       "      <td>The Kitchen God's Wife</td>\n",
       "      <td>Amy Tan</td>\n",
       "      <td>1991</td>\n",
       "      <td>Putnam Pub Group</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>book_0440234743</td>\n",
       "      <td>The Testament</td>\n",
       "      <td>John Grisham</td>\n",
       "      <td>1999</td>\n",
       "      <td>Dell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>book_0452264464</td>\n",
       "      <td>Beloved (Plume Contemporary Fiction)</td>\n",
       "      <td>Toni Morrison</td>\n",
       "      <td>1994</td>\n",
       "      <td>Plume</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               ISBN                                         Book-Title  \\\n",
       "1   book_0002005018                                       Clara Callan   \n",
       "3   book_0374157065  Flu: The Story of the Great Influenza Pandemic...   \n",
       "5   book_0399135782                             The Kitchen God's Wife   \n",
       "18  book_0440234743                                      The Testament   \n",
       "19  book_0452264464               Beloved (Plume Contemporary Fiction)   \n",
       "\n",
       "             Book-Author  Year-Of-Publication              Publisher  \n",
       "1   Richard Bruce Wright                 2001  HarperFlamingo Canada  \n",
       "3       Gina Bari Kolata                 1999   Farrar Straus Giroux  \n",
       "5                Amy Tan                 1991       Putnam Pub Group  \n",
       "18          John Grisham                 1999                   Dell  \n",
       "19         Toni Morrison                 1994                  Plume  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Book to Book Matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Groups: 12168\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User-ID</th>\n",
       "      <th>ISBN_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>user_100004</td>\n",
       "      <td>[book_0345339703, book_0399146652, book_042508...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>user_100009</td>\n",
       "      <td>[book_0060392452, book_0060977337, book_031298...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>user_100053</td>\n",
       "      <td>[book_0312422156, book_0316769487, book_038549...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>user_100088</td>\n",
       "      <td>[book_0006550576, book_0007110928, book_006016...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>user_100115</td>\n",
       "      <td>[book_0060173289, book_0399144463, book_044047...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       User-ID                                          ISBN_list\n",
       "0  user_100004  [book_0345339703, book_0399146652, book_042508...\n",
       "1  user_100009  [book_0060392452, book_0060977337, book_031298...\n",
       "2  user_100053  [book_0312422156, book_0316769487, book_038549...\n",
       "3  user_100088  [book_0006550576, book_0007110928, book_006016...\n",
       "4  user_100115  [book_0060173289, book_0399144463, book_044047..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Group books which are read from same user\n",
    "book_groups_raw = ratings.groupby('User-ID')\n",
    "book_groups = pd.DataFrame(\n",
    "    data={\n",
    "        \"User-ID\": list(book_groups_raw.groups.keys()),\n",
    "        \"ISBN_list\": list(book_groups_raw.ISBN.apply(list)),\n",
    "    }\n",
    ")\n",
    "# Eliminate if user has read one book\n",
    "book_groups = book_groups[book_groups['ISBN_list'].apply(len) > 1].reset_index(drop=True)\n",
    "print(f\"Number of Groups: {book_groups.shape[0]}\")\n",
    "book_groups.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Matches: 2811412\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>main_ISBN</th>\n",
       "      <th>similar_ISBN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>book_0345339703</td>\n",
       "      <td>book_0399146652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>book_0345339703</td>\n",
       "      <td>book_0425083837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>book_0345339703</td>\n",
       "      <td>book_0439064872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>book_0345339703</td>\n",
       "      <td>book_059035342X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>book_0399146652</td>\n",
       "      <td>book_0425083837</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         main_ISBN     similar_ISBN\n",
       "0  book_0345339703  book_0399146652\n",
       "1  book_0345339703  book_0425083837\n",
       "2  book_0345339703  book_0439064872\n",
       "3  book_0345339703  book_059035342X\n",
       "4  book_0399146652  book_0425083837"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "book_matches = []\n",
    "# for each book in our isbn_list we generate pairs\n",
    "for isbn_list in book_groups['ISBN_list'].values:\n",
    "    if len(isbn_list) <= 1:\n",
    "        continue\n",
    "    for i, main_isbn in enumerate(isbn_list[:-1]):\n",
    "        for similar_isbn in isbn_list[i+1:]:\n",
    "            book_matches.append([main_isbn, similar_isbn])\n",
    "\n",
    "# Dataset generation and visualization\n",
    "book_pairs_dataset = pd.DataFrame(book_matches, columns=[\"main_ISBN\", \"similar_ISBN\"])\n",
    "data_size = book_pairs_dataset.shape[0]\n",
    "print(f\"Number of Matches: {data_size}\")\n",
    "book_pairs_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>main_ISBN</th>\n",
       "      <th>similar_ISBN</th>\n",
       "      <th>main_Book-Title</th>\n",
       "      <th>main_Book-Author</th>\n",
       "      <th>main_Year-Of-Publication</th>\n",
       "      <th>main_Publisher</th>\n",
       "      <th>similar_Book-Title</th>\n",
       "      <th>similar_Book-Author</th>\n",
       "      <th>similar_Year-Of-Publication</th>\n",
       "      <th>similar_Publisher</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>book_0345339703</td>\n",
       "      <td>book_0399146652</td>\n",
       "      <td>The Fellowship of the Ring (The Lord of the Ri...</td>\n",
       "      <td>J.R.R. TOLKIEN</td>\n",
       "      <td>1986</td>\n",
       "      <td>Del Rey</td>\n",
       "      <td>The Cat Who Smelled a Rat</td>\n",
       "      <td>Lilian Jackson Braun</td>\n",
       "      <td>2001</td>\n",
       "      <td>Putnam Publishing Group</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>book_0064400557</td>\n",
       "      <td>book_0399146652</td>\n",
       "      <td>Charlotte's Web (Trophy Newbery)</td>\n",
       "      <td>E. B. White</td>\n",
       "      <td>1974</td>\n",
       "      <td>HarperTrophy</td>\n",
       "      <td>The Cat Who Smelled a Rat</td>\n",
       "      <td>Lilian Jackson Braun</td>\n",
       "      <td>2001</td>\n",
       "      <td>Putnam Publishing Group</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>book_0064400042</td>\n",
       "      <td>book_0399146652</td>\n",
       "      <td>On the Banks of Plum Creek</td>\n",
       "      <td>Laura Ingalls Wilder</td>\n",
       "      <td>1953</td>\n",
       "      <td>HarperTrophy</td>\n",
       "      <td>The Cat Who Smelled a Rat</td>\n",
       "      <td>Lilian Jackson Braun</td>\n",
       "      <td>2001</td>\n",
       "      <td>Putnam Publishing Group</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>book_0385492081</td>\n",
       "      <td>book_0399146652</td>\n",
       "      <td>Into Thin Air : A Personal Account of the Mt. ...</td>\n",
       "      <td>JON KRAKAUER</td>\n",
       "      <td>1998</td>\n",
       "      <td>Anchor</td>\n",
       "      <td>The Cat Who Smelled a Rat</td>\n",
       "      <td>Lilian Jackson Braun</td>\n",
       "      <td>2001</td>\n",
       "      <td>Putnam Publishing Group</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>book_0061092614</td>\n",
       "      <td>book_0399146652</td>\n",
       "      <td>Finding Moon</td>\n",
       "      <td>Tony Hillerman</td>\n",
       "      <td>1996</td>\n",
       "      <td>HarperTorch</td>\n",
       "      <td>The Cat Who Smelled a Rat</td>\n",
       "      <td>Lilian Jackson Braun</td>\n",
       "      <td>2001</td>\n",
       "      <td>Putnam Publishing Group</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         main_ISBN     similar_ISBN  \\\n",
       "0  book_0345339703  book_0399146652   \n",
       "1  book_0064400557  book_0399146652   \n",
       "2  book_0064400042  book_0399146652   \n",
       "3  book_0385492081  book_0399146652   \n",
       "4  book_0061092614  book_0399146652   \n",
       "\n",
       "                                     main_Book-Title      main_Book-Author  \\\n",
       "0  The Fellowship of the Ring (The Lord of the Ri...        J.R.R. TOLKIEN   \n",
       "1                   Charlotte's Web (Trophy Newbery)           E. B. White   \n",
       "2                         On the Banks of Plum Creek  Laura Ingalls Wilder   \n",
       "3  Into Thin Air : A Personal Account of the Mt. ...          JON KRAKAUER   \n",
       "4                                       Finding Moon        Tony Hillerman   \n",
       "\n",
       "   main_Year-Of-Publication main_Publisher         similar_Book-Title  \\\n",
       "0                      1986        Del Rey  The Cat Who Smelled a Rat   \n",
       "1                      1974   HarperTrophy  The Cat Who Smelled a Rat   \n",
       "2                      1953   HarperTrophy  The Cat Who Smelled a Rat   \n",
       "3                      1998         Anchor  The Cat Who Smelled a Rat   \n",
       "4                      1996    HarperTorch  The Cat Who Smelled a Rat   \n",
       "\n",
       "    similar_Book-Author  similar_Year-Of-Publication        similar_Publisher  \n",
       "0  Lilian Jackson Braun                         2001  Putnam Publishing Group  \n",
       "1  Lilian Jackson Braun                         2001  Putnam Publishing Group  \n",
       "2  Lilian Jackson Braun                         2001  Putnam Publishing Group  \n",
       "3  Lilian Jackson Braun                         2001  Putnam Publishing Group  \n",
       "4  Lilian Jackson Braun                         2001  Putnam Publishing Group  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Our final dataset to train our model \n",
    "# Main book features\n",
    "main_books = books.rename(columns=lambda x: 'main_' + x if x != 'ISBN' else x).copy()\n",
    "book_pairs = pd.merge(book_pairs_dataset, main_books,\n",
    "                              left_on='main_ISBN',\n",
    "                              right_on='ISBN')\n",
    "book_pairs.drop(\"ISBN\", axis=1, inplace=True)\n",
    "\n",
    "# Similar book features\n",
    "similar_books = books.rename(columns=lambda x: 'similar_' + x if x != 'ISBN' else x).copy()\n",
    "book_pairs = pd.merge(book_pairs, similar_books,\n",
    "                              left_on='similar_ISBN',\n",
    "                              right_on='ISBN')\n",
    "\n",
    "book_pairs.drop(\"ISBN\", axis=1, inplace=True)\n",
    "book_pairs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Convert Dataset to TFDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "# Pairs dataset\n",
    "book_pairs_final = tf.data.Dataset.from_tensor_slices({\n",
    "    # main book features\n",
    "    'main_ISBN': tf.cast(book_pairs['main_ISBN'], dtype=tf.string),\n",
    "    'main_Book-Author': tf.cast(book_pairs['main_Book-Author'], dtype=tf.string),\n",
    "    'main_Publisher': tf.cast(book_pairs['main_Publisher'], dtype=tf.string),\n",
    "\n",
    "    # similar book features\n",
    "    'similar_ISBN': tf.cast(book_pairs['similar_ISBN'], dtype=tf.string),\n",
    "    'similar_Book-Author': tf.cast(book_pairs['similar_Book-Author'], dtype=tf.string),\n",
    "    'similar_Publisher': tf.cast(book_pairs['similar_Publisher'], dtype=tf.string),\n",
    "})\n",
    "\n",
    "book_pairs_final = book_pairs_final.batch(batch_size)\n",
    "# Book information dataset\n",
    "book_infos = tf.data.Dataset.from_tensor_slices({\n",
    "    'ISBN': tf.cast(books['ISBN'], dtype=tf.string),\n",
    "    'Book-Title': tf.cast(books['Book-Title'], dtype=tf.string),\n",
    "    'Book-Author': tf.cast(books['Book-Author'], dtype=tf.string),\n",
    "    'Year-Of-Publication': tf.cast(books['Year-Of-Publication'], dtype=tf.int32),\n",
    "    'Publisher': tf.cast(books['Publisher'], dtype=tf.string),\n",
    "})\n",
    "book_infos = book_infos.batch(batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(1002)\n",
    "train_percentage = 0.8\n",
    "batch_count = (data_size + batch_size - 1) // batch_size\n",
    "shuffled = book_pairs_final.shuffle(batch_count, seed=42, reshuffle_each_iteration=False)\n",
    "\n",
    "train = shuffled.take(int(batch_count * train_percentage))\n",
    "test = shuffled.skip(int(batch_count * train_percentage)).take(int(batch_count * (1 - train_percentage)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Model Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lookup Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique books 10000\n",
      "Number of unique authors 3585\n",
      "Number of unique publishers 912\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of unique books {books['ISBN'].nunique()}\")\n",
    "print(f\"Number of unique authors {books['Book-Author'].nunique()}\")\n",
    "print(f\"Number of unique publishers {books['Publisher'].nunique()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Book ID Model\n",
    "book_embedding_dimension = 32\n",
    "unique_book_ids = books['ISBN'].unique()\n",
    "book_id_model = tf.keras.Sequential([\n",
    "  tf.keras.layers.StringLookup(\n",
    "      vocabulary=unique_book_ids, mask_token=None),\n",
    "  tf.keras.layers.Embedding(len(unique_book_ids) + 1, book_embedding_dimension)\n",
    "])\n",
    "\n",
    "\n",
    "# Author Model\n",
    "author_embedding_dimension = 16\n",
    "unique_book_authors = books['Book-Author'].unique()\n",
    "book_author_model = tf.keras.Sequential([\n",
    "  tf.keras.layers.StringLookup(\n",
    "      vocabulary=unique_book_authors, mask_token=None),\n",
    "  tf.keras.layers.Embedding(len(unique_book_authors) + 1, author_embedding_dimension)\n",
    "])\n",
    "\n",
    "# Publisher Model\n",
    "publisher_embedding_dimension = 8\n",
    "unique_book_publishers = books['Publisher'].unique()\n",
    "book_publisher_model = tf.keras.Sequential([\n",
    "  tf.keras.layers.StringLookup(\n",
    "      vocabulary=unique_book_publishers, mask_token=None),\n",
    "  tf.keras.layers.Embedding(len(unique_book_publishers) + 1, publisher_embedding_dimension)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(16,), dtype=float32, numpy=\n",
       "array([-0.00047473, -0.04359952, -0.04364598,  0.01775734,  0.04634592,\n",
       "       -0.02750721,  0.0186587 , -0.00193182,  0.02367789,  0.03915879,\n",
       "       -0.0384239 ,  0.04421388,  0.03307794,  0.03446558, -0.0056635 ,\n",
       "        0.01931131], dtype=float32)>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Author Embedding Visualization\n",
    "book_author_model('Richard Bruce Wright')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Book Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BookModel(tfrs.Model):\n",
    "\n",
    "  def __init__(self, book_id_model, book_author_model, book_publisher_model):\n",
    "    super().__init__()\n",
    "    # assigning sub models to convert ids to embeddings\n",
    "    self.book_id_model = book_id_model\n",
    "    self.book_author_model = book_author_model\n",
    "    self.book_publisher_model = book_publisher_model\n",
    "\n",
    "  def call(self, features: Dict[Text, tf.Tensor]):\n",
    "\n",
    "    # concatenation of embeddings\n",
    "    return tf.concat([\n",
    "        self.book_id_model(features[\"ISBN\"]),\n",
    "        self.book_author_model(features[\"Book-Author\"]),\n",
    "        self.book_publisher_model(features[\"Publisher\"])\n",
    "    ], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 56), dtype=float32, numpy=\n",
       "array([[ 0.01757706, -0.03391429,  0.04606818, -0.04963733,  0.04298634,\n",
       "         0.03143705, -0.02430425, -0.03428488, -0.02209013, -0.00144886,\n",
       "        -0.00032824, -0.0030693 , -0.04322591, -0.04820166, -0.03648701,\n",
       "        -0.02583539,  0.00283287, -0.04777063, -0.03393644,  0.02638796,\n",
       "        -0.03396711,  0.0222959 ,  0.0016482 ,  0.01727309, -0.03328496,\n",
       "        -0.01860482, -0.00124011,  0.00588206, -0.0386134 ,  0.02654059,\n",
       "         0.04035938,  0.04684517, -0.00047473, -0.04359952, -0.04364598,\n",
       "         0.01775734,  0.04634592, -0.02750721,  0.0186587 , -0.00193182,\n",
       "         0.02367789,  0.03915879, -0.0384239 ,  0.04421388,  0.03307794,\n",
       "         0.03446558, -0.0056635 ,  0.01931131,  0.04907965, -0.0287883 ,\n",
       "        -0.01515704, -0.02734662,  0.00217923, -0.00456314,  0.046264  ,\n",
       "         0.0201872 ]], dtype=float32)>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialization of our book model\n",
    "book_model = BookModel(book_id_model, book_author_model, book_publisher_model)\n",
    "\n",
    "# Sample example\n",
    "book_model({'Book-Author': ['Richard Bruce Wright'],\n",
    "            'Book-Title': ['Clara Callan'],\n",
    "            'ISBN': ['book_0002005018'],\n",
    "            'Publisher': ['HarperFlamingo Canada'],\n",
    "            'Year-Of-Publication': [2001]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics & Task\n",
    "metrics = tfrs.metrics.FactorizedTopK(candidates=book_infos.map(lambda features: book_model(features)))\n",
    "task = tfrs.tasks.Retrieval(metrics=metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Book to Book Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Book2BookModel(tfrs.Model):\n",
    "    def __init__(self, book_id_model, book_author_model, book_publisher_model, output_dimension=64):\n",
    "        super().__init__()\n",
    "        self.book_id_model = book_id_model\n",
    "        self.book_author_model = book_author_model\n",
    "        self.book_publisher_model = book_publisher_model\n",
    "        # combining book model with output dimension to fix output dimension\n",
    "        self.book_model_raw = BookModel(self.book_id_model,\n",
    "                                        self.book_author_model,\n",
    "                                        self.book_publisher_model)\n",
    "        self.book_model = tf.keras.Sequential([self.book_model_raw,\n",
    "                                               tf.keras.layers.Dense(output_dimension)])\n",
    "        # Metrics & Task\n",
    "        self.candidates = book_infos.map(lambda x: self.book_model(x))\n",
    "        metrics = tfrs.metrics.FactorizedTopK(candidates=self.candidates)\n",
    "        # negative sampling also applied\n",
    "        self.task = tfrs.tasks.Retrieval(metrics=metrics,\n",
    "                                        num_hard_negatives=5)\n",
    "    \n",
    "    def compute_loss(self, features: Dict[Text, tf.Tensor], training=False):\n",
    "        # Generation of main book embedding from main item features\n",
    "        main_book_embedding = self.book_model({'ISBN':features['main_ISBN'],\n",
    "                                          'Book-Author': features['main_Book-Author'],\n",
    "                                          'Publisher': features['main_Publisher']})\n",
    "\n",
    "        # Generation of similar book embedding from similar item features\n",
    "        similar_book_embedding = self.book_model({'ISBN':features['similar_ISBN'],\n",
    "                                                 'Book-Author': features['similar_Book-Author'],\n",
    "                                                 'Publisher': features['similar_Publisher']})\n",
    "\n",
    "        # loss and the metric calculation\n",
    "        # compute metrics set false to skyrocket training speed\n",
    "        return self.task(main_book_embedding,\n",
    "                         similar_book_embedding,\n",
    "                         compute_metrics=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Book to Book Model initialization\n",
    "book2book_model = Book2BookModel(book_id_model, book_author_model, book_publisher_model)\n",
    "book2book_model.compile(optimizer=tf.keras.optimizers.legacy.Adagrad(learning_rate=0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "8786/8786 [==============================] - 18s 2ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 461.1721 - regularization_loss: 0.0000e+00 - total_loss: 461.1721\n",
      "Epoch 2/5\n",
      "8786/8786 [==============================] - 19s 2ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 458.6495 - regularization_loss: 0.0000e+00 - total_loss: 458.6495\n",
      "Epoch 3/5\n",
      "8786/8786 [==============================] - 17s 1ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 458.6432 - regularization_loss: 0.0000e+00 - total_loss: 458.6432\n",
      "Epoch 4/5\n",
      "8786/8786 [==============================] - 18s 2ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 458.6426 - regularization_loss: 0.0000e+00 - total_loss: 458.6426\n",
      "Epoch 5/5\n",
      "8786/8786 [==============================] - 18s 2ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 458.6424 - regularization_loss: 0.0000e+00 - total_loss: 458.6424\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2cd41b7c0>"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book2book_model.fit(train, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ISBN</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>book_0002005018</td>\n",
       "      <td>[-0.0017602745, -0.0013976829, -0.0021855175, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>book_0374157065</td>\n",
       "      <td>[-0.0007435555, -7.0164606e-06, 0.00071950734,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>book_0399135782</td>\n",
       "      <td>[0.00020831745, 9.385678e-05, 0.00038658825, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>book_0440234743</td>\n",
       "      <td>[-8.501603e-05, -0.000242146, 4.2675376e-05, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>book_0452264464</td>\n",
       "      <td>[-0.00013961342, -0.00032210685, -3.2549055e-0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              ISBN                                          embedding\n",
       "0  book_0002005018  [-0.0017602745, -0.0013976829, -0.0021855175, ...\n",
       "1  book_0374157065  [-0.0007435555, -7.0164606e-06, 0.00071950734,...\n",
       "2  book_0399135782  [0.00020831745, 9.385678e-05, 0.00038658825, 0...\n",
       "3  book_0440234743  [-8.501603e-05, -0.000242146, 4.2675376e-05, 0...\n",
       "4  book_0452264464  [-0.00013961342, -0.00032210685, -3.2549055e-0..."
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function to apply the model to each book feature set and return ISBN with embeddings\n",
    "def extract_embeddings_with_isbn(features):\n",
    "    embeddings = book2book_model.book_model(features)\n",
    "    return features['ISBN'], embeddings\n",
    "\n",
    "# Mapping the function over the dataset\n",
    "book_embeddings = book_infos.map(extract_embeddings_with_isbn)\n",
    "isbn_list = []\n",
    "embeddings_list = []\n",
    "\n",
    "# Example to inspect or use the embeddings with ISBNs\n",
    "for isbn, embedding in book_embeddings:\n",
    "    isbn_list.extend(list(isbn.numpy().astype(str)))  \n",
    "    embeddings_list.extend(list(embedding.numpy()))\n",
    "\n",
    "book_embedding_dataset = pd.DataFrame({'ISBN':isbn_list, 'embedding':embeddings_list})\n",
    "book_embedding_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_embedding_dict = dict(zip(book_embedding_dataset.ISBN, book_embedding_dataset.embedding))\n",
    "book_title_dict = dict(zip(books['ISBN'], books['Book-Title']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = output_dimension\n",
    "\n",
    "num_elements = book_embedding_dataset.shape[0]\n",
    "# hnswlib initialization with cosine similarity\n",
    "p = hnswlib.Index(space='cosine', dim=dim)\n",
    "\n",
    "p.init_index(max_elements=num_elements, ef_construction=100, M=16)\n",
    "\n",
    "p.set_ef(10)\n",
    "\n",
    "embeddings = np.vstack(book_embedding_dataset[\"embedding\"].values)\n",
    "p.add_items(embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similar Book Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def book_search(isbn, k=3):\n",
    "    \"\"\"Gets input embeddings and return top k similar items\"\"\"\n",
    "\n",
    "    # Generate embedding for the user query\n",
    "    query_embedding = book_embedding_dict[isbn]\n",
    "\n",
    "    if query_embedding is None:\n",
    "        return \"Invalid query or embedding generation failed.\"\n",
    "\n",
    "    labels, _ = p.knn_query(query_embedding, k=k+1)\n",
    "    results = book_embedding_dataset.iloc[list(labels[0][1:])].to_dict('records')\n",
    "    similar_isbns = [similar_isbn['ISBN'] for similar_isbn in results]\n",
    "    return similar_isbns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main Book:\n",
      "-Clara Callan \n",
      "Similar Books:\n",
      "1. The Rose and The Beast: Fairy Tales Retold\n",
      "2. One Hit Wonderland\n",
      "3. HTML 4 for the World Wide Web, Fourth Edition: Visual QuickStart Guide (4th Edition)\n"
     ]
    }
   ],
   "source": [
    "# Visualization of Recommendation\n",
    "main_book = book_embedding_dataset['ISBN'][0]\n",
    "print(f\"Main Book:\\n-{book_title_dict[main_book]} \\nSimilar Books:\")\n",
    "\n",
    "similar_books = book_search(main_book)\n",
    "for i, similar_book in enumerate(similar_books):\n",
    "    print(f\"{i+1}. {book_title_dict[similar_book]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommendations & Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top Products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Popular Books:\n",
      "1. The Return of the King (The Lord of the Rings, Part 3)\n",
      "2. Harry Potter and the Prisoner of Azkaban (Book 3)\n",
      "3. On the Road\n",
      "4. Harry Potter and the Goblet of Fire (Book 4)\n",
      "5. Key of Valor (Roberts, Nora. Key Trilogy, 3.)\n",
      "6. The Stand (The Complete and Uncut Edition)\n",
      "7. Harry Potter and the Order of the Phoenix (Book 5)\n",
      "8. Anne of Avonlea (Anne of Green Gables Novels (Paperback))\n",
      "9. The Fellowship of the Ring (The Lord of the Rings, Part 1)\n",
      "10. The Hobbit : The Enchanting Prelude to The Lord of the Rings\n"
     ]
    }
   ],
   "source": [
    "def get_popular_books(df_ratings):\n",
    "  # Calculate the number of ratings for each movie\n",
    "  rating_counts = df_ratings['ISBN'].value_counts().reset_index()\n",
    "  rating_counts.columns = ['ISBN', 'rating_count']\n",
    "\n",
    "  # Get the most frequently rated movies\n",
    "  min_ratings_threshold = rating_counts['rating_count'].quantile(0.95)\n",
    "\n",
    "  # Filter movies based on the minimum number of ratings\n",
    "  popular_movies = ratings.merge(rating_counts, on='ISBN')\n",
    "  popular_movies = popular_movies[popular_movies['rating_count'] >= min_ratings_threshold]\n",
    "\n",
    "  # Calculate the average rating for each movie\n",
    "  average_ratings = popular_movies.groupby('ISBN')['Book-Rating'].mean().reset_index()\n",
    "\n",
    "  # Get the top 10 rated movies\n",
    "  top_10_movies = list(average_ratings.sort_values('Book-Rating', ascending=False).head(10).ISBN.values)\n",
    "  return top_10_movies\n",
    "\n",
    "popular_books = get_popular_books(ratings)\n",
    "print(\"Popular Books:\")\n",
    "for i, popular_book in enumerate(popular_books):\n",
    "  print(f\"{i+1}. {book_title_dict[popular_book]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similar Products "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to apply the model to each book feature set and return ISBN with embeddings\n",
    "def extract_pairs(features):\n",
    "    return features['main_ISBN'], features['similar_ISBN']\n",
    "\n",
    "main_isbn_list = []\n",
    "similar_isbn_list = []\n",
    "\n",
    "book_pairs_test = test.map(extract_pairs)\n",
    "for main_isbn, similar_isbn in book_pairs_test:\n",
    "    main_isbn_list.extend(list(main_isbn.numpy().astype(str)))  \n",
    "    similar_isbn_list.extend(list(similar_isbn.numpy().astype(str)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "popular_reco_results = []\n",
    "two_tower_reco_results = []\n",
    "k = 10\n",
    "\n",
    "for main_isbn, similar_isbn in zip(main_isbn_list, similar_isbn_list):\n",
    "    popular_reco_check = np.isin(popular_books, similar_isbn).astype(int)\n",
    "    popular_reco_results.append(popular_reco_check)\n",
    "    # get embedding based recommendations\n",
    "    similar_books = book_search(main_isbn, k=k)\n",
    "    two_tower_check = np.isin(similar_books, similar_isbn).astype(int)\n",
    "    two_tower_reco_results.append(two_tower_check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Two Tower NDCG result at top 3: 0.0021\n",
      "Popular recommendation NDCG result at top 3: 0.0\n",
      "\n",
      "\n",
      "Two Tower NDCG result at top 5: 0.0027\n",
      "Popular recommendation NDCG result at top 5: 0.001\n",
      "\n",
      "\n",
      "Two Tower NDCG result at top 10: 0.0035\n",
      "Popular recommendation NDCG result at top 10: 0.0021\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import ndcg_score\n",
    "\n",
    "# Since we have already sorted our recommendations\n",
    "# An array that represent our recommendation scores is used.\n",
    "representative_array = [[i for i in range(k, 0, -1)]] * len(two_tower_reco_results)\n",
    "\n",
    "for k in [3, 5, 10]:\n",
    "  two_tower_result = ndcg_score(two_tower_reco_results,\n",
    "                                  representative_array, k=k)\n",
    "  popular_result = ndcg_score(popular_reco_results,\n",
    "                              representative_array, k=k)\n",
    "  \n",
    "  print(f\"Two Tower NDCG result at top {k}: {round(two_tower_result, 4)}\")\n",
    "  print(f\"Popular recommendation NDCG result at top {k}: {round(popular_result, 4)}\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "- https://www.tensorflow.org/recommenders/examples/basic_retrieval\n",
    "- https://www.tensorflow.org/recommenders/examples/featurization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "feast",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
