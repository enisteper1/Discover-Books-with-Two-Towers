{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Preprocessing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pprint\n",
    "from transformers import DistilBertTokenizer, DistilBertModel\n",
    "\n",
    "from typing import Dict, Text\n",
    "import tensorflow as tf\n",
    "import tensorflow_recommenders as tfrs\n",
    "import hnswlib\n",
    "\n",
    "# min rating to consider\n",
    "min_rating = 8\n",
    "# top k popular books\n",
    "top_k_popular_books = 10_000\n",
    "\n",
    "# parameters\n",
    "output_dimension = 64\n",
    "batch_size = 256\n",
    "learning_rate = 0.1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/66/b29gfxwj3tb43t74fmwm28nmrsc95x/T/ipykernel_18184/2153888385.py:2: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  books = pd.read_csv(\"dataset/Books.csv\")\n"
     ]
    }
   ],
   "source": [
    "# Datasets\n",
    "books = pd.read_csv(\"dataset/Books.csv\")\n",
    "\n",
    "ratings = pd.read_csv(\"dataset/Ratings.csv\")\n",
    "\n",
    "users = pd.read_csv(\"dataset/Users.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Users: 46810\n",
      "Number of Books: 41743\n",
      "Number of Ratings: 85918\n"
     ]
    }
   ],
   "source": [
    "# Visualization and Type Standardization\n",
    "users[\"User-ID\"] = users[\"User-ID\"].apply(lambda x: f\"user_{x}\")\n",
    "\n",
    "# Filter out books with missing or corrupted information\n",
    "books[\"ISBN\"] = books[\"ISBN\"].apply(lambda x: f\"book_{x}\")\n",
    "books.drop([\"Image-URL-S\", \"Image-URL-M\", \"Image-URL-L\"], axis=1, inplace=True)\n",
    "books.dropna(inplace=True)\n",
    "\n",
    "def clean_year(year):\n",
    "    try:\n",
    "        return int(year)\n",
    "    except ValueError:\n",
    "        return -1\n",
    "\n",
    "books['Year-Of-Publication'] = books['Year-Of-Publication'].apply(clean_year)\n",
    "books = books[books['Year-Of-Publication'] != -1].reset_index(drop=True)\n",
    "books = books.drop_duplicates(subset='Book-Title')\n",
    "\n",
    "\n",
    "ratings[\"ISBN\"] = ratings[\"ISBN\"].apply(lambda x: f\"book_{x}\")\n",
    "ratings[\"User-ID\"] = ratings[\"User-ID\"].apply(lambda x: f\"user_{x}\")\n",
    "ratings[\"Book-Rating\"] = ratings[\"Book-Rating\"].apply(lambda x: float(x))\n",
    "ratings = ratings[ratings.ISBN.isin(books['ISBN'].unique())]\n",
    "# Filtering products for simplicity\n",
    "\n",
    "# Only consider high ratings\n",
    "ratings = ratings[ratings[\"Book-Rating\"] >= 7]\n",
    "# Remove outlier users\n",
    "outlier_threshold = ratings['User-ID'].value_counts().quantile(0.9)\n",
    "user_rating_count_dict = ratings['User-ID'].value_counts().to_dict()\n",
    "ratings['rate_count'] = ratings['User-ID'].map(user_rating_count_dict)\n",
    "ratings = ratings[ratings['rate_count'] <= outlier_threshold]\n",
    "\n",
    "# Consider user & book that has rating in ratings dataset\n",
    "books = books[books.ISBN.isin(ratings['ISBN'].unique())]\n",
    "users = users[users['User-ID'].isin(ratings['User-ID'].unique())]\n",
    "print(f\"Number of Users: {users['User-ID'].nunique()}\")\n",
    "print(f\"Number of Books: {books['ISBN'].nunique()}\")\n",
    "print(f\"Number of Ratings: {ratings.shape[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ISBN</th>\n",
       "      <th>Book-Title</th>\n",
       "      <th>Book-Author</th>\n",
       "      <th>Year-Of-Publication</th>\n",
       "      <th>Publisher</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>book_0002005018</td>\n",
       "      <td>Clara Callan</td>\n",
       "      <td>Richard Bruce Wright</td>\n",
       "      <td>2001</td>\n",
       "      <td>HarperFlamingo Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>book_0060973129</td>\n",
       "      <td>Decision in Normandy</td>\n",
       "      <td>Carlo D'Este</td>\n",
       "      <td>1991</td>\n",
       "      <td>HarperPerennial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>book_0374157065</td>\n",
       "      <td>Flu: The Story of the Great Influenza Pandemic...</td>\n",
       "      <td>Gina Bari Kolata</td>\n",
       "      <td>1999</td>\n",
       "      <td>Farrar Straus Giroux</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>book_0399135782</td>\n",
       "      <td>The Kitchen God's Wife</td>\n",
       "      <td>Amy Tan</td>\n",
       "      <td>1991</td>\n",
       "      <td>Putnam Pub Group</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>book_1558746218</td>\n",
       "      <td>A Second Chicken Soup for the Woman's Soul (Ch...</td>\n",
       "      <td>Jack Canfield</td>\n",
       "      <td>1998</td>\n",
       "      <td>Health Communications</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               ISBN                                         Book-Title  \\\n",
       "1   book_0002005018                                       Clara Callan   \n",
       "2   book_0060973129                               Decision in Normandy   \n",
       "3   book_0374157065  Flu: The Story of the Great Influenza Pandemic...   \n",
       "5   book_0399135782                             The Kitchen God's Wife   \n",
       "14  book_1558746218  A Second Chicken Soup for the Woman's Soul (Ch...   \n",
       "\n",
       "             Book-Author  Year-Of-Publication              Publisher  \n",
       "1   Richard Bruce Wright                 2001  HarperFlamingo Canada  \n",
       "2           Carlo D'Este                 1991        HarperPerennial  \n",
       "3       Gina Bari Kolata                 1999   Farrar Straus Giroux  \n",
       "5                Amy Tan                 1991       Putnam Pub Group  \n",
       "14         Jack Canfield                 1998  Health Communications  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Book to Book Matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Groups: 16055\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User-ID</th>\n",
       "      <th>ISBN_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>user_100004</td>\n",
       "      <td>[book_0345339703, book_0399146652, book_043906...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>user_10003</td>\n",
       "      <td>[book_068483068X, book_0743446593]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>user_100035</td>\n",
       "      <td>[book_0440211727, book_0671759310]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>user_100053</td>\n",
       "      <td>[book_0312422156, book_0316769487, book_038549...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>user_100066</td>\n",
       "      <td>[book_0060953713, book_0385722206, book_039309...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       User-ID                                          ISBN_list\n",
       "0  user_100004  [book_0345339703, book_0399146652, book_043906...\n",
       "1   user_10003                 [book_068483068X, book_0743446593]\n",
       "2  user_100035                 [book_0440211727, book_0671759310]\n",
       "3  user_100053  [book_0312422156, book_0316769487, book_038549...\n",
       "4  user_100066  [book_0060953713, book_0385722206, book_039309..."
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Group books which are read from same user\n",
    "book_groups_raw = ratings.groupby('User-ID')\n",
    "book_groups = pd.DataFrame(\n",
    "    data={\n",
    "        \"User-ID\": list(book_groups_raw.groups.keys()),\n",
    "        \"ISBN_list\": list(book_groups_raw.ISBN.apply(list)),\n",
    "    }\n",
    ")\n",
    "# Eliminate if user has read one book\n",
    "book_groups = book_groups[book_groups['ISBN_list'].apply(len) > 1].reset_index(drop=True)\n",
    "print(f\"Number of Groups: {book_groups.shape[0]}\")\n",
    "book_groups.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Matches: 90940\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>main_ISBN</th>\n",
       "      <th>similar_ISBN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>book_0345339703</td>\n",
       "      <td>book_0399146652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>book_0345339703</td>\n",
       "      <td>book_0439064872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>book_0345339703</td>\n",
       "      <td>book_059035342X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>book_0399146652</td>\n",
       "      <td>book_0439064872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>book_0399146652</td>\n",
       "      <td>book_059035342X</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         main_ISBN     similar_ISBN\n",
       "0  book_0345339703  book_0399146652\n",
       "1  book_0345339703  book_0439064872\n",
       "2  book_0345339703  book_059035342X\n",
       "3  book_0399146652  book_0439064872\n",
       "4  book_0399146652  book_059035342X"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "book_matches = []\n",
    "# for each book in our isbn_list we generate pairs\n",
    "for isbn_list in book_groups['ISBN_list'].values:\n",
    "    if len(isbn_list) <= 1:\n",
    "        continue\n",
    "    for i, main_isbn in enumerate(isbn_list[:-1]):\n",
    "        for similar_isbn in isbn_list[i+1:]:\n",
    "            book_matches.append([main_isbn, similar_isbn])\n",
    "\n",
    "# Dataset generation and visualization\n",
    "book_pairs_dataset = pd.DataFrame(book_matches, columns=[\"main_ISBN\", \"similar_ISBN\"])\n",
    "data_size = book_pairs_dataset.shape[0]\n",
    "print(f\"Number of Matches: {data_size}\")\n",
    "book_pairs_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>main_ISBN</th>\n",
       "      <th>similar_ISBN</th>\n",
       "      <th>main_Book-Title</th>\n",
       "      <th>main_Book-Author</th>\n",
       "      <th>main_Year-Of-Publication</th>\n",
       "      <th>main_Publisher</th>\n",
       "      <th>similar_Book-Title</th>\n",
       "      <th>similar_Book-Author</th>\n",
       "      <th>similar_Year-Of-Publication</th>\n",
       "      <th>similar_Publisher</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>book_0345339703</td>\n",
       "      <td>book_0399146652</td>\n",
       "      <td>The Fellowship of the Ring (The Lord of the Ri...</td>\n",
       "      <td>J.R.R. TOLKIEN</td>\n",
       "      <td>1986</td>\n",
       "      <td>Del Rey</td>\n",
       "      <td>The Cat Who Smelled a Rat</td>\n",
       "      <td>Lilian Jackson Braun</td>\n",
       "      <td>2001</td>\n",
       "      <td>Putnam Publishing Group</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>book_0316284955</td>\n",
       "      <td>book_0399146652</td>\n",
       "      <td>White Oleander : A Novel (Oprah's Book Club)</td>\n",
       "      <td>Janet Fitch</td>\n",
       "      <td>2000</td>\n",
       "      <td>Back Bay Books</td>\n",
       "      <td>The Cat Who Smelled a Rat</td>\n",
       "      <td>Lilian Jackson Braun</td>\n",
       "      <td>2001</td>\n",
       "      <td>Putnam Publishing Group</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>book_0312278586</td>\n",
       "      <td>book_0399146652</td>\n",
       "      <td>The Nanny Diaries: A Novel</td>\n",
       "      <td>Emma McLaughlin</td>\n",
       "      <td>2002</td>\n",
       "      <td>St. Martin's Press</td>\n",
       "      <td>The Cat Who Smelled a Rat</td>\n",
       "      <td>Lilian Jackson Braun</td>\n",
       "      <td>2001</td>\n",
       "      <td>Putnam Publishing Group</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>book_0316666343</td>\n",
       "      <td>book_0399146652</td>\n",
       "      <td>The Lovely Bones: A Novel</td>\n",
       "      <td>Alice Sebold</td>\n",
       "      <td>2002</td>\n",
       "      <td>Little, Brown</td>\n",
       "      <td>The Cat Who Smelled a Rat</td>\n",
       "      <td>Lilian Jackson Braun</td>\n",
       "      <td>2001</td>\n",
       "      <td>Putnam Publishing Group</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>book_0140293248</td>\n",
       "      <td>book_0399146652</td>\n",
       "      <td>The Girls' Guide to Hunting and Fishing</td>\n",
       "      <td>Melissa Bank</td>\n",
       "      <td>2000</td>\n",
       "      <td>Penguin Books</td>\n",
       "      <td>The Cat Who Smelled a Rat</td>\n",
       "      <td>Lilian Jackson Braun</td>\n",
       "      <td>2001</td>\n",
       "      <td>Putnam Publishing Group</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         main_ISBN     similar_ISBN  \\\n",
       "0  book_0345339703  book_0399146652   \n",
       "1  book_0316284955  book_0399146652   \n",
       "2  book_0312278586  book_0399146652   \n",
       "3  book_0316666343  book_0399146652   \n",
       "4  book_0140293248  book_0399146652   \n",
       "\n",
       "                                     main_Book-Title main_Book-Author  \\\n",
       "0  The Fellowship of the Ring (The Lord of the Ri...   J.R.R. TOLKIEN   \n",
       "1       White Oleander : A Novel (Oprah's Book Club)      Janet Fitch   \n",
       "2                         The Nanny Diaries: A Novel  Emma McLaughlin   \n",
       "3                          The Lovely Bones: A Novel     Alice Sebold   \n",
       "4            The Girls' Guide to Hunting and Fishing     Melissa Bank   \n",
       "\n",
       "   main_Year-Of-Publication      main_Publisher         similar_Book-Title  \\\n",
       "0                      1986             Del Rey  The Cat Who Smelled a Rat   \n",
       "1                      2000      Back Bay Books  The Cat Who Smelled a Rat   \n",
       "2                      2002  St. Martin's Press  The Cat Who Smelled a Rat   \n",
       "3                      2002       Little, Brown  The Cat Who Smelled a Rat   \n",
       "4                      2000       Penguin Books  The Cat Who Smelled a Rat   \n",
       "\n",
       "    similar_Book-Author  similar_Year-Of-Publication        similar_Publisher  \n",
       "0  Lilian Jackson Braun                         2001  Putnam Publishing Group  \n",
       "1  Lilian Jackson Braun                         2001  Putnam Publishing Group  \n",
       "2  Lilian Jackson Braun                         2001  Putnam Publishing Group  \n",
       "3  Lilian Jackson Braun                         2001  Putnam Publishing Group  \n",
       "4  Lilian Jackson Braun                         2001  Putnam Publishing Group  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Our final dataset to train our model \n",
    "# Main book features\n",
    "main_books = books.rename(columns=lambda x: 'main_' + x if x != 'ISBN' else x).copy()\n",
    "book_pairs = pd.merge(book_pairs_dataset, main_books,\n",
    "                              left_on='main_ISBN',\n",
    "                              right_on='ISBN')\n",
    "book_pairs.drop(\"ISBN\", axis=1, inplace=True)\n",
    "\n",
    "# Similar book features\n",
    "similar_books = books.rename(columns=lambda x: 'similar_' + x if x != 'ISBN' else x).copy()\n",
    "book_pairs = pd.merge(book_pairs, similar_books,\n",
    "                              left_on='similar_ISBN',\n",
    "                              right_on='ISBN')\n",
    "\n",
    "book_pairs.drop(\"ISBN\", axis=1, inplace=True)\n",
    "book_pairs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Convert Dataset to TFDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "# Pairs dataset\n",
    "book_pairs_final = tf.data.Dataset.from_tensor_slices({\n",
    "    # main book features\n",
    "    'main_ISBN': tf.cast(book_pairs['main_ISBN'], dtype=tf.string),\n",
    "    'main_Book-Title': tf.cast(book_pairs['main_Book-Title'], dtype=tf.string),\n",
    "    'main_Book-Author': tf.cast(book_pairs['main_Book-Author'], dtype=tf.string),\n",
    "    'main_Publisher': tf.cast(book_pairs['main_Publisher'], dtype=tf.string),\n",
    "\n",
    "    # similar book features\n",
    "    'similar_ISBN': tf.cast(book_pairs['similar_ISBN'], dtype=tf.string),\n",
    "    'similar_Book-Title': tf.cast(book_pairs['similar_Book-Title'], dtype=tf.string),\n",
    "    'similar_Book-Author': tf.cast(book_pairs['similar_Book-Author'], dtype=tf.string),\n",
    "    'similar_Publisher': tf.cast(book_pairs['similar_Publisher'], dtype=tf.string),\n",
    "})\n",
    "\n",
    "book_pairs_final = book_pairs_final.batch(batch_size)\n",
    "# Book information dataset\n",
    "book_infos = tf.data.Dataset.from_tensor_slices({\n",
    "    'ISBN': tf.cast(books['ISBN'], dtype=tf.string),\n",
    "    'Book-Title': tf.cast(books['Book-Title'], dtype=tf.string),\n",
    "    'Book-Author': tf.cast(books['Book-Author'], dtype=tf.string),\n",
    "    'Year-Of-Publication': tf.cast(books['Year-Of-Publication'], dtype=tf.int32),\n",
    "    'Publisher': tf.cast(books['Publisher'], dtype=tf.string),\n",
    "})\n",
    "book_infos = book_infos.batch(batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(1002)\n",
    "train_percentage = 0.8\n",
    "batch_count = (data_size + batch_size - 1) // batch_size\n",
    "shuffled = book_pairs_final.shuffle(batch_count, seed=42, reshuffle_each_iteration=False)\n",
    "\n",
    "train = shuffled.take(int(batch_count * train_percentage))\n",
    "test = shuffled.skip(int(batch_count * train_percentage)).take(int(batch_count * (1 - train_percentage)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Model Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lookup Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique books 41743\n",
      "Number of unique titles 41743\n",
      "Number of unique authors 21935\n",
      "Number of unique publishers 5234\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of unique books {books['ISBN'].nunique()}\")\n",
    "print(f\"Number of unique titles {books['Book-Title'].nunique()}\")\n",
    "print(f\"Number of unique authors {books['Book-Author'].nunique()}\")\n",
    "print(f\"Number of unique publishers {books['Publisher'].nunique()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_distilbert_embeddings(book_titles):\n",
    "    # convert bytes to string\n",
    "    book_titles = [title.decode('utf-8') for title in book_titles.numpy()]\n",
    "    # set inputs\n",
    "    input_ids = tokenizer(book_titles, padding=True, truncation=True, return_tensors='pt', max_length=20)\n",
    "    # generate embeddings\n",
    "    outputs = bert_model(input_ids['input_ids'])\n",
    "    # get last layer\n",
    "    last_hidden_state = outputs.last_hidden_state\n",
    "\n",
    "    # mean vector is required and also padded values should be excluded\n",
    "    input_mask = tf.cast(input_ids['attention_mask'], tf.float32)\n",
    "    input_mask_expanded = tf.expand_dims(input_mask, -1)\n",
    "    sum_embeddings = tf.reduce_sum(last_hidden_state.detach().numpy() * input_mask_expanded, axis=1)\n",
    "    sum_mask = tf.reduce_sum(input_mask_expanded, axis=1)\n",
    "    mean_embeddings = sum_embeddings / sum_mask\n",
    "    return book_titles, mean_embeddings\n",
    "\n",
    "bert_model = DistilBertModel.from_pretrained('distilbert-base-uncased')\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "title_list = []\n",
    "title_embeddings = []\n",
    "\n",
    "# Process batches of book titles to get embeddings\n",
    "for batch in book_infos:\n",
    "    book_titles, embeddings = batch_distilbert_embeddings(batch['Book-Title'])\n",
    "    title_list.extend(book_titles)\n",
    "    title_embeddings.extend(embeddings)\n",
    "\n",
    "title_embeddings_df = pd.DataFrame({'Book-Title':title_list, 'embedding':title_embeddings})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Book ID Model\n",
    "book_embedding_dimension = 32\n",
    "unique_book_ids = books['ISBN'].unique()\n",
    "book_id_model = tf.keras.Sequential([\n",
    "  tf.keras.layers.StringLookup(\n",
    "      vocabulary=unique_book_ids, mask_token=None),\n",
    "  tf.keras.layers.Embedding(len(unique_book_ids) + 1, book_embedding_dimension)\n",
    "])\n",
    "\n",
    "\n",
    "# Author Model\n",
    "author_embedding_dimension = 16\n",
    "unique_book_authors = books['Book-Author'].unique()\n",
    "book_author_model = tf.keras.Sequential([\n",
    "  tf.keras.layers.StringLookup(\n",
    "      vocabulary=unique_book_authors, mask_token=None),\n",
    "  tf.keras.layers.Embedding(len(unique_book_authors) + 1, author_embedding_dimension)\n",
    "])\n",
    "\n",
    "# Publisher Model\n",
    "publisher_embedding_dimension = 8\n",
    "unique_book_publishers = books['Publisher'].unique()\n",
    "book_publisher_model = tf.keras.Sequential([\n",
    "  tf.keras.layers.StringLookup(\n",
    "      vocabulary=unique_book_publishers, mask_token=None),\n",
    "  tf.keras.layers.Embedding(len(unique_book_publishers) + 1, publisher_embedding_dimension)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Book Title Model\n",
    "title_output_dim = len(title_embeddings[0])\n",
    "# An embedding if there are any unknown text input occurs\n",
    "unknown_embedding = np.random.uniform(-1, 1, size=title_output_dim)\n",
    "title_embeddings.insert(0, unknown_embedding)\n",
    "book_title_model = tf.keras.Sequential([\n",
    "  tf.keras.layers.StringLookup(\n",
    "      vocabulary=title_list, mask_token=None),\n",
    "  tf.keras.layers.Embedding(\n",
    "                    input_dim=len(title_list) + 1,\n",
    "                    output_dim=title_output_dim,\n",
    "                    embeddings_initializer=tf.keras.initializers.Constant(np.vstack(title_embeddings)),\n",
    "                    trainable=False)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(16,), dtype=float32, numpy=\n",
       "array([-0.00374892,  0.03112172, -0.01137679,  0.01890567,  0.00999472,\n",
       "        0.03013868, -0.00890771,  0.00090703, -0.03488296,  0.02796206,\n",
       "        0.0466506 ,  0.0105405 ,  0.04664585,  0.03104696, -0.04421418,\n",
       "       -0.02597226], dtype=float32)>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Author Embedding Visualization\n",
    "book_author_model('Richard Bruce Wright')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Book Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BookModel(tfrs.Model):\n",
    "\n",
    "  def __init__(self, book_id_model, book_title_model, book_author_model, book_publisher_model):\n",
    "    super().__init__()\n",
    "    # assigning sub models to convert ids to embeddings\n",
    "    self.book_id_model = book_id_model\n",
    "    self.book_title_model = book_title_model\n",
    "    self.book_author_model = book_author_model\n",
    "    self.book_publisher_model = book_publisher_model\n",
    "\n",
    "  def call(self, features: Dict[Text, tf.Tensor]):\n",
    "\n",
    "    # concatenation of embeddings\n",
    "    return tf.concat([\n",
    "        self.book_id_model(features[\"ISBN\"]),\n",
    "        self.book_title_model(features['Book-Title']),\n",
    "        self.book_author_model(features[\"Book-Author\"]),\n",
    "        self.book_publisher_model(features[\"Publisher\"]),\n",
    "    ], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 824), dtype=float32, numpy=\n",
       "array([[ 3.51698734e-02, -2.78519467e-03,  2.30444595e-03,\n",
       "         3.12348045e-02,  1.89812295e-02, -3.99783365e-02,\n",
       "         1.17850304e-02,  4.74686362e-02, -2.13208795e-02,\n",
       "         3.40786614e-02,  1.61033608e-02, -1.28562227e-02,\n",
       "        -3.41572911e-02,  5.08170202e-03,  3.42685096e-02,\n",
       "        -4.27875519e-02,  3.15414332e-02, -4.68228236e-02,\n",
       "        -3.08310986e-02,  3.12447436e-02,  3.53118442e-02,\n",
       "         4.04568762e-03, -2.01974399e-02, -4.46451306e-02,\n",
       "        -4.10275683e-02,  1.61081813e-02,  4.51924242e-02,\n",
       "         1.22807994e-02,  2.67754234e-02,  4.98669781e-02,\n",
       "         3.81411426e-02,  1.59688480e-02,  2.23631971e-02,\n",
       "        -1.04747519e-01,  1.30989566e-01, -1.22102417e-01,\n",
       "        -1.27681702e-01, -3.13720465e-01,  2.34213993e-01,\n",
       "        -1.50504902e-01,  1.26815423e-01,  6.83802515e-02,\n",
       "         2.24938430e-02, -9.28697884e-02,  2.29649872e-01,\n",
       "         4.44575539e-03, -3.85670871e-01, -1.34370908e-01,\n",
       "         6.19845986e-02, -1.07834220e-01,  1.76023230e-01,\n",
       "        -3.12032640e-01,  3.34067456e-02,  6.54628277e-02,\n",
       "         2.62774289e-01,  1.59449726e-01,  4.89499941e-02,\n",
       "         7.77188987e-02, -6.99378997e-02,  3.05823386e-01,\n",
       "         1.86342560e-02, -2.23970219e-01, -1.45591851e-02,\n",
       "        -1.56441376e-01,  4.54078335e-03, -4.35007289e-02,\n",
       "        -2.81242281e-01,  8.05684552e-02,  3.32431465e-01,\n",
       "         5.06447181e-02, -7.37167969e-02, -1.32697761e-01,\n",
       "        -3.39423656e-01, -4.06622589e-01, -5.45335896e-02,\n",
       "         1.81274265e-01,  1.47696389e-02, -2.57466644e-01,\n",
       "        -3.82636935e-01,  2.67026424e-01, -1.57875806e-01,\n",
       "         1.05628707e-01, -3.44880074e-01,  2.96476901e-01,\n",
       "         1.25030205e-01,  8.83753970e-02, -1.54589638e-02,\n",
       "         3.80574286e-01, -2.02941090e-01, -1.60995796e-01,\n",
       "         4.00982462e-02, -5.84453233e-02,  6.18400760e-02,\n",
       "        -1.18819829e-02, -1.76675953e-02,  9.20653902e-03,\n",
       "         8.28884020e-02,  3.09441745e-01,  3.60953286e-02,\n",
       "         1.36072069e-01, -3.78095776e-01,  8.19840953e-02,\n",
       "        -1.77299410e-01, -2.00514123e-01,  2.37729959e-02,\n",
       "         4.17448021e-02, -3.77873518e-02,  1.33892924e-01,\n",
       "        -1.01730086e-01,  6.39792085e-02,  2.32789785e-01,\n",
       "         8.35293531e-02, -1.43934742e-01,  1.69302784e-02,\n",
       "        -9.47651416e-02, -3.54846492e-02,  8.89116898e-02,\n",
       "        -8.66347924e-02,  3.00481617e-02,  1.29961520e-01,\n",
       "        -9.13012773e-03,  3.56172621e-01, -7.54660815e-02,\n",
       "        -1.38726100e-01,  2.56365091e-01,  8.12665373e-02,\n",
       "         1.23627171e-01,  3.52590978e-02, -2.41007045e-01,\n",
       "         5.56274764e-02, -1.19658830e-02,  2.33879477e-01,\n",
       "         6.06892481e-02,  1.09320864e-01, -7.94003382e-02,\n",
       "         1.20380744e-01, -1.40575811e-01, -1.45317033e-01,\n",
       "        -2.16532703e-02, -9.26429555e-02, -1.92448586e-01,\n",
       "        -3.42091858e-01,  5.91354147e-02,  9.86379907e-02,\n",
       "         1.48235083e-01, -1.46538019e-04, -3.84183452e-02,\n",
       "        -3.84263307e-01,  3.55856423e-03,  8.01897198e-02,\n",
       "         1.01621352e-01, -5.04048243e-02, -1.52821511e-01,\n",
       "        -1.11217044e-01,  2.27950618e-01,  3.89649719e-01,\n",
       "         9.28038582e-02,  2.11019188e-01, -2.16962337e-01,\n",
       "        -8.52847770e-02,  1.91640824e-01, -1.50874229e-02,\n",
       "        -1.98063478e-01,  1.68832883e-01, -1.12900257e-01,\n",
       "         7.27021098e-02,  8.63712728e-02, -1.48237675e-01,\n",
       "         8.04536566e-02,  1.31755725e-01, -2.00251818e-01,\n",
       "        -6.87445253e-02, -1.70353070e-01,  3.29823792e-01,\n",
       "        -2.30005890e-01, -1.62915036e-01,  3.82427067e-01,\n",
       "         4.12934124e-01, -8.71090032e-03, -5.38169928e-02,\n",
       "         3.38913985e-02, -2.26889297e-01,  6.69633374e-02,\n",
       "        -8.48118216e-02, -1.98643059e-01,  1.17871165e-01,\n",
       "        -2.70706058e-01, -1.56124337e-02, -3.20175350e-01,\n",
       "        -3.82288694e-02, -6.06885925e-02,  2.87962347e-01,\n",
       "         6.99843187e-03, -6.09448850e-02,  1.36902913e-01,\n",
       "        -2.10047029e-02,  3.59809510e-02, -4.13559489e-02,\n",
       "        -2.08482891e-01,  1.92952722e-01, -8.28837305e-02,\n",
       "         4.75177579e-02, -2.50466138e-01, -3.73688936e-01,\n",
       "         1.64437309e-01, -1.95029050e-01, -3.49542320e-01,\n",
       "        -5.80964088e-02,  2.03162953e-01,  1.41418323e-01,\n",
       "        -1.35404468e-01,  3.58437784e-02, -2.11789131e+00,\n",
       "         4.04571354e-01,  1.41783565e-01, -2.72951841e-01,\n",
       "        -7.68440813e-02,  1.73147842e-01, -4.59601164e-01,\n",
       "         2.09723786e-01,  2.97418842e-03, -1.13264859e-01,\n",
       "        -8.78746957e-02,  6.88955411e-02, -3.55706424e-01,\n",
       "         2.30469704e-01,  2.13108778e-01, -3.30698416e-02,\n",
       "        -4.51622494e-02, -5.27743921e-02, -1.93474144e-01,\n",
       "        -1.30091339e-01,  7.31592998e-02,  1.54866114e-01,\n",
       "         5.39527424e-02,  1.06131628e-01,  4.22847345e-02,\n",
       "         3.90409529e-01,  3.02334934e-01,  1.11952916e-01,\n",
       "         1.62688300e-01,  3.10989507e-02, -3.58014405e-01,\n",
       "        -3.80946584e-02,  1.92035228e-01,  5.57752838e-03,\n",
       "         5.29368520e-02, -1.18855894e-01,  5.89064434e-02,\n",
       "        -1.12036392e-01, -3.46961012e-03, -2.65341885e-02,\n",
       "        -1.32430941e-01, -8.89472812e-02, -2.25173429e-01,\n",
       "         2.02278420e-01,  1.57342374e-01, -1.87366977e-01,\n",
       "         3.20833623e-01, -1.11912653e-01,  2.06820697e-01,\n",
       "        -1.35953963e-01,  2.12639958e-01, -2.27540419e-01,\n",
       "         2.77722418e-01, -5.63764684e-02, -2.21009806e-01,\n",
       "        -1.15340210e-01,  9.81339440e-02, -8.64093453e-02,\n",
       "        -1.09742321e-01, -3.05877149e-01, -8.60272720e-02,\n",
       "         6.69511780e-02,  2.26779148e-01,  8.59332085e-02,\n",
       "        -1.80671379e-01, -1.80929437e-01, -1.85985014e-01,\n",
       "         7.97566622e-02, -8.66731182e-02, -1.37741014e-01,\n",
       "        -2.32081369e-01, -5.14630497e-01, -5.83025208e-03,\n",
       "        -1.42783731e-01,  5.96130490e-02, -2.14964032e-01,\n",
       "         7.64760971e-02,  4.85784002e-02,  4.25941169e-01,\n",
       "         2.60093808e-03,  2.13595822e-01,  2.72826493e-01,\n",
       "         3.77696693e-01, -2.26994697e-02, -2.12137669e-01,\n",
       "         1.18182480e-01,  1.27319530e-01,  7.04086497e-02,\n",
       "         1.00713037e-01,  8.98365825e-02, -8.71957392e-02,\n",
       "        -4.43547964e-02,  4.07472700e-02, -3.73756588e-01,\n",
       "        -1.50481075e-01, -1.01224996e-01,  2.91267037e-01,\n",
       "         1.39374822e-01, -1.05755903e-01, -9.36144590e-02,\n",
       "        -1.62692722e-02,  2.82650560e-01,  2.97588378e-01,\n",
       "        -5.06628938e-02,  7.56733790e-02, -2.31625631e-01,\n",
       "         3.01910075e-03,  4.78914380e-03,  1.42966673e-01,\n",
       "        -3.99284929e-01,  1.41469212e-02,  3.27621758e-01,\n",
       "         2.68138707e-01, -1.23201627e-02,  4.63948905e-01,\n",
       "        -1.96545959e-01,  4.39163595e-01,  2.66428173e-01,\n",
       "        -1.66236803e-01, -8.31550211e-02, -2.39812851e-01,\n",
       "         4.01053950e-02,  1.06264509e-01,  5.84325418e-02,\n",
       "         2.58589983e-01,  2.16577202e-01,  1.29964262e-01,\n",
       "        -6.00078814e-02, -3.74430847e+00, -7.90438130e-02,\n",
       "        -1.93328448e-02, -4.19698179e-01,  3.16969335e-01,\n",
       "        -2.75453508e-01,  2.84467518e-01, -1.65263250e-01,\n",
       "         2.56497860e-02,  2.32882768e-01, -1.01003483e-01,\n",
       "         1.03062831e-01,  4.20567617e-02,  5.62763400e-02,\n",
       "        -7.65146986e-02,  2.44821664e-02, -2.02867433e-01,\n",
       "        -1.62381828e-01, -2.75252819e-01,  5.99072576e-02,\n",
       "        -1.05462506e-01, -7.54684135e-02,  1.46303505e-01,\n",
       "         2.44110078e-01,  1.99213177e-01,  1.75228640e-01,\n",
       "        -1.28798291e-01,  6.22553639e-02, -1.49502475e-02,\n",
       "        -5.45755634e-03, -2.63488054e-01, -2.37764642e-01,\n",
       "        -1.84801742e-01,  1.59459263e-01,  1.67885534e-02,\n",
       "        -7.49315545e-02, -6.21258728e-02, -2.22133994e-01,\n",
       "         1.15873359e-01, -1.70748845e-01, -8.69018584e-02,\n",
       "        -1.32434577e-01, -3.45640704e-02, -1.58520490e-01,\n",
       "         4.59929109e-02, -2.10712522e-01, -2.67625362e-01,\n",
       "         5.11992685e-02, -1.87259056e-02,  3.01462084e-01,\n",
       "         6.52818903e-02,  6.84768781e-02,  2.03203127e-01,\n",
       "        -2.74136961e-01, -1.18371055e-01, -9.69193596e-03,\n",
       "         2.43160576e-01,  1.45881906e-01, -8.53072405e-02,\n",
       "        -2.71374047e-01,  4.21411172e-02,  2.52034776e-02,\n",
       "        -2.96962261e-01,  1.38207883e-01, -7.44317248e-02,\n",
       "        -1.78383082e-01,  1.80458166e-02, -1.20154977e-01,\n",
       "        -6.00043051e-02,  6.20328411e-02, -4.05832589e-01,\n",
       "        -2.16924027e-01,  2.83635147e-02, -7.11770535e-01,\n",
       "        -1.31145447e-01, -7.36250430e-02, -3.99994195e-01,\n",
       "         3.83431464e-01,  7.58155882e-02,  2.04298347e-01,\n",
       "        -1.73262864e-01, -6.33283630e-02,  3.13856781e-01,\n",
       "         8.70527178e-02, -3.00312102e-01,  8.64779502e-02,\n",
       "        -9.95401591e-02, -2.32813954e-01,  1.13311328e-01,\n",
       "        -4.49324362e-02,  2.50101566e-01,  1.78612143e-01,\n",
       "         1.44138664e-01, -7.54680410e-02,  2.15364605e-01,\n",
       "         5.28908610e-01,  7.29846209e-02, -1.84937298e-01,\n",
       "         4.39799398e-01, -1.64017588e-01,  2.67296974e-02,\n",
       "        -2.38071278e-01,  3.04513037e-01, -1.97430909e-01,\n",
       "         2.30902150e-01, -2.99629085e-02, -5.90022385e-01,\n",
       "         2.92048696e-02, -6.06139414e-02,  3.06306477e-03,\n",
       "         3.75759989e-01, -8.79756585e-02,  5.39056435e-02,\n",
       "        -1.24319457e-01, -3.57381031e-02, -3.29189777e-01,\n",
       "         1.18948147e-01,  3.05159628e-01,  1.16007224e-01,\n",
       "         1.42435312e-01, -8.13574567e-02,  2.20803291e-01,\n",
       "        -2.10428238e-02, -1.63087338e-01,  4.47034836e-05,\n",
       "         1.34765670e-01,  1.22736655e-01,  1.18505977e-01,\n",
       "        -1.41270295e-01, -3.11725177e-02,  2.67408248e-02,\n",
       "        -2.07383186e-01,  1.18325375e-01, -2.68231809e-01,\n",
       "        -3.29595171e-02,  4.42033783e-02, -8.27184319e-02,\n",
       "        -1.13489188e-01, -2.66523361e-01,  1.33514032e-01,\n",
       "         2.98275445e-02,  5.08513227e-02, -2.90068090e-01,\n",
       "         1.78960815e-01,  2.37144619e-01,  5.36429062e-02,\n",
       "        -1.09970890e-01,  6.94254488e-02,  2.44817212e-01,\n",
       "         8.81128311e-02,  9.05000940e-02, -3.61870855e-01,\n",
       "         2.91292518e-01, -3.63874763e-01,  5.08660264e-02,\n",
       "        -1.94336012e-01,  1.50703937e-01, -2.07116887e-01,\n",
       "        -5.37808716e-01,  3.74588102e-01, -7.08211809e-02,\n",
       "        -2.76202440e-01, -3.67759727e-02,  4.05278131e-02,\n",
       "        -2.37917140e-01, -5.47028184e-02,  3.59841198e-01,\n",
       "        -5.65107688e-02, -1.68794394e-02,  9.00973231e-02,\n",
       "         1.35127470e-01, -4.66645360e-02, -4.33385745e-02,\n",
       "         2.84294542e-02,  2.61602108e-03,  3.53787988e-01,\n",
       "         1.00854896e-01, -3.04781944e-02, -9.03517902e-02,\n",
       "         3.39295238e-01,  4.64695580e-02, -2.53687620e-01,\n",
       "         1.15666285e-01,  1.11378625e-01,  3.74074519e-01,\n",
       "         2.63397872e-01,  1.24982193e-01, -3.60702127e-01,\n",
       "         6.47030845e-02,  2.02015311e-01,  2.82262117e-02,\n",
       "        -3.46835226e-01, -2.76382416e-01, -3.61152478e-02,\n",
       "        -4.80816979e-03, -1.74808934e-01,  4.89682764e-01,\n",
       "        -4.38621035e-03,  2.25544423e-01,  3.09170485e-01,\n",
       "         1.36677235e-01, -6.77637011e-02, -4.13280487e-01,\n",
       "         1.75439976e-02,  1.94030538e-01,  6.09303266e-03,\n",
       "         1.99188203e-01,  1.98327824e-01,  1.15663312e-01,\n",
       "        -2.92704195e-01, -1.10367164e-01, -1.57037854e-01,\n",
       "         7.99733847e-02, -4.84610498e-02,  1.83499441e-01,\n",
       "        -1.37118012e-01,  9.65257920e-03,  3.36966291e-03,\n",
       "         2.14522406e-01, -3.35436106e-01, -1.82458386e-01,\n",
       "        -2.08475739e-01, -7.74114132e-02, -1.60844922e-01,\n",
       "        -6.78435564e-02, -2.14041233e-01, -1.64643556e-01,\n",
       "         8.97722170e-02, -1.12233952e-01,  5.02715120e-03,\n",
       "         4.90669534e-02, -2.56875098e-01,  9.71996970e-03,\n",
       "        -4.78226580e-02, -3.33470711e-03, -9.71355438e-02,\n",
       "        -1.37049764e-01, -3.27339955e-02, -1.26471400e-01,\n",
       "         2.92003930e-01,  1.20628238e-01, -2.58981854e-01,\n",
       "         8.89431089e-02, -1.72618665e-02,  5.45798428e-02,\n",
       "         1.15892030e-01, -1.97498232e-01,  1.19764708e-01,\n",
       "         1.88815072e-01,  2.21788883e-04,  3.03171873e-01,\n",
       "         1.73591375e-02, -6.34135008e-02, -4.37105268e-01,\n",
       "         1.70599565e-01, -2.52470791e-01, -9.91548523e-02,\n",
       "         2.46613830e-01, -1.53073147e-01,  1.42739145e-02,\n",
       "        -1.51967078e-01,  1.07937781e-02,  1.00778937e-01,\n",
       "         2.09899694e-02, -5.69629557e-02,  2.08722427e-01,\n",
       "        -5.98945003e-03,  7.60395378e-02,  7.41978595e-03,\n",
       "        -1.79180354e-01,  1.01724252e-01,  1.06344208e-01,\n",
       "         1.72522306e-01,  1.75296128e-01, -1.88128799e-01,\n",
       "         7.13530928e-02, -2.27827668e-01, -6.24752454e-02,\n",
       "        -2.38817498e-01, -3.51908863e-01,  5.53821445e-01,\n",
       "         2.45401412e-01,  6.62444234e-02, -1.02136634e-01,\n",
       "         4.62197393e-01, -5.76589331e-02,  1.61508173e-01,\n",
       "        -1.37429684e-01,  1.68125942e-01, -3.97769213e-01,\n",
       "         3.45017731e-01,  1.70837969e-01, -1.77163575e-02,\n",
       "         1.93759441e-01, -1.91669270e-01,  3.95614207e-01,\n",
       "         4.12749946e-02,  3.71715367e-01, -1.67559981e-01,\n",
       "         9.73799080e-03, -2.70173609e-01,  7.70060439e-03,\n",
       "         3.35787497e-02,  1.16637066e-01, -1.87027514e-01,\n",
       "         2.92028897e-02,  1.89595968e-01, -2.37380907e-01,\n",
       "        -1.15754470e-01,  4.89881128e-01, -5.77422976e-02,\n",
       "        -3.94798368e-02,  3.51290464e-01,  4.61490393e-01,\n",
       "        -1.37789205e-01, -1.80583164e-01, -2.31073759e-02,\n",
       "        -3.63332510e-01,  7.69587755e-02,  7.25858957e-02,\n",
       "        -2.80027241e-02,  1.41410038e-01,  1.64202303e-01,\n",
       "         1.96556091e-01,  1.64838359e-01, -4.78649922e-02,\n",
       "        -2.82201618e-01, -9.21948925e-02, -6.57701343e-02,\n",
       "         1.96619436e-01,  2.54032433e-01,  1.07269347e-01,\n",
       "         2.10387677e-01, -1.87862031e-02, -3.83477584e-02,\n",
       "        -7.00841397e-02,  8.90787691e-02,  5.26058674e-03,\n",
       "        -2.11131684e-02, -4.02957760e-02, -1.07832644e-02,\n",
       "        -1.85239618e-03,  2.15283036e-01,  1.12870172e-01,\n",
       "         1.57145828e-01,  9.53173451e-03,  2.49722600e-01,\n",
       "        -1.22004792e-01,  5.55838123e-02,  2.03994457e-02,\n",
       "         1.24997616e-01,  1.25597313e-01,  9.43784863e-02,\n",
       "        -4.70949858e-02, -2.24713832e-01, -1.36275262e-01,\n",
       "        -1.56008955e-02,  2.77432263e-01,  1.90288916e-01,\n",
       "        -3.14385086e-01, -1.46682501e-01,  1.40539318e-01,\n",
       "         1.69712722e-01, -1.66715473e-01, -2.06666533e-02,\n",
       "         1.73366368e-01,  1.97780177e-01, -1.04252994e-01,\n",
       "        -3.15298468e-01,  1.77081019e-01,  1.72087237e-01,\n",
       "         2.66758412e-01,  7.21034631e-02,  1.48367375e-01,\n",
       "        -2.62157507e-02, -1.56189352e-01, -1.46402925e-01,\n",
       "        -1.44764021e-01, -1.53897479e-01, -2.20794648e-01,\n",
       "         1.95990771e-01, -3.42719257e-01, -7.03997463e-02,\n",
       "        -3.23592722e-02, -3.39660011e-02, -4.61861044e-01,\n",
       "        -1.74580306e-01,  4.17907946e-02, -3.96117896e-01,\n",
       "        -7.72797912e-02,  3.67061228e-01, -1.26660556e-01,\n",
       "         4.84624729e-02,  3.28925923e-02, -7.89014846e-02,\n",
       "         7.83769265e-02, -3.08151240e-03, -1.02650627e-01,\n",
       "         3.20844650e-01,  1.57907099e-01,  3.60709131e-01,\n",
       "        -1.60175227e-02, -2.95800537e-01,  1.94126099e-01,\n",
       "         2.50173718e-01,  4.07250375e-02,  9.04993415e-02,\n",
       "         2.13006541e-01, -2.66279638e-01, -1.16457798e-01,\n",
       "        -1.48736417e-01, -9.94792134e-02, -7.50549138e-01,\n",
       "         2.63061315e-01, -2.87255347e-01,  2.57315598e-02,\n",
       "         2.40333438e-01,  7.87865669e-02,  6.03828318e-02,\n",
       "        -1.83614284e-01,  2.07489319e-02, -2.22000882e-01,\n",
       "         1.30743951e-01,  2.65134633e-01,  4.56478186e-02,\n",
       "         1.21355869e-01, -3.67046520e-02,  1.58239499e-01,\n",
       "        -6.09144941e-02, -9.22197029e-02,  2.42088556e-01,\n",
       "         8.54447708e-02,  5.80834132e-03,  1.68206275e-01,\n",
       "         1.18415533e-02, -1.51733786e-01,  2.14377239e-01,\n",
       "        -5.95184341e-02,  1.02810860e-01, -8.35291594e-02,\n",
       "        -1.38261065e-01,  1.57494590e-01, -8.93573016e-02,\n",
       "         2.60123163e-01, -1.22756696e+00, -8.24261159e-02,\n",
       "         2.41041943e-01, -1.25701338e-01, -2.57469356e-01,\n",
       "        -2.24360853e-01, -1.11057341e-01, -1.16084836e-01,\n",
       "         6.46543875e-02, -3.22033584e-01,  1.26105621e-01,\n",
       "        -3.08437258e-01, -1.61890343e-01, -6.75307121e-03,\n",
       "         1.65452987e-01, -1.77457780e-01, -3.74891609e-03,\n",
       "         3.11217196e-02, -1.13767870e-02,  1.89056657e-02,\n",
       "         9.99472290e-03,  3.01386751e-02, -8.90771300e-03,\n",
       "         9.07026231e-04, -3.48829627e-02,  2.79620551e-02,\n",
       "         4.66505997e-02,  1.05404966e-02,  4.66458462e-02,\n",
       "         3.10469605e-02, -4.42141779e-02, -2.59722602e-02,\n",
       "        -5.64233214e-03,  3.33893187e-02,  3.63350026e-02,\n",
       "         4.73934077e-02,  2.00901367e-02,  4.89078276e-02,\n",
       "        -1.04417577e-02, -3.66981998e-02]], dtype=float32)>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialization of our book model\n",
    "book_model = BookModel(book_id_model, book_title_model, book_author_model, book_publisher_model)\n",
    "\n",
    "# Sample example\n",
    "book_model({'Book-Author': ['Richard Bruce Wright'],\n",
    "            'Book-Title': ['Clara Callan'],\n",
    "            'ISBN': ['book_0002005018'],\n",
    "            'Publisher': ['HarperFlamingo Canada'],\n",
    "            'Year-Of-Publication': [2001]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics & Task\n",
    "metrics = tfrs.metrics.FactorizedTopK(candidates=book_infos.map(lambda features: book_model(features)))\n",
    "task = tfrs.tasks.Retrieval(metrics=metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Book to Book Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Book2BookModel(tfrs.Model):\n",
    "    def __init__(self, book_id_model, book_title_model, book_author_model, book_publisher_model, output_dimension=64):\n",
    "        super().__init__()\n",
    "        self.book_id_model = book_id_model\n",
    "        self.book_title_model = book_title_model\n",
    "        self.book_author_model = book_author_model\n",
    "        self.book_publisher_model = book_publisher_model\n",
    "        # combining book model with output dimension to fix output dimension\n",
    "        self.book_model_raw = BookModel(self.book_id_model,\n",
    "                                        self.book_title_model,\n",
    "                                        self.book_author_model,\n",
    "                                        self.book_publisher_model)\n",
    "        self.book_model = tf.keras.Sequential([self.book_model_raw,\n",
    "                                               tf.keras.layers.Dense(output_dimension)])\n",
    "        # Metrics & Task\n",
    "        self.candidates = book_infos.map(lambda x: self.book_model(x))\n",
    "        metrics = tfrs.metrics.FactorizedTopK(candidates=self.candidates)\n",
    "        # negative sampling also applied\n",
    "        self.task = tfrs.tasks.Retrieval(metrics=metrics,\n",
    "                                        num_hard_negatives=5)\n",
    "    \n",
    "    def compute_loss(self, features: Dict[Text, tf.Tensor], training=True):\n",
    "        # Generation of main book embedding from main item features\n",
    "        main_book_embedding = self.book_model({'ISBN':features['main_ISBN'],\n",
    "                                               'Book-Title':features['main_Book-Title'],\n",
    "                                               'Book-Author': features['main_Book-Author'],\n",
    "                                               'Publisher': features['main_Publisher']})\n",
    "\n",
    "        # Generation of similar book embedding from similar item features\n",
    "        similar_book_embedding = self.book_model({'ISBN':features['similar_ISBN'],\n",
    "                                                  'Book-Title':features['similar_Book-Title'],\n",
    "                                                  'Book-Author': features['similar_Book-Author'],\n",
    "                                                  'Publisher': features['similar_Publisher']})\n",
    "\n",
    "        # loss and the metric calculation\n",
    "        # compute metrics set false to skyrock training speed\n",
    "        return self.task(main_book_embedding,\n",
    "                         similar_book_embedding,\n",
    "                         compute_metrics=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Book to Book Model initialization\n",
    "book2book_model = Book2BookModel(book_id_model,\n",
    "                                 book_title_model,\n",
    "                                 book_author_model,\n",
    "                                 book_publisher_model)\n",
    "book2book_model.compile(optimizer=tf.keras.optimizers.legacy.Adagrad(learning_rate=0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "284/284 [==============================] - 8s 19ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 4655.8043 - regularization_loss: 0.0000e+00 - total_loss: 4655.8043\n",
      "Epoch 2/5\n",
      "284/284 [==============================] - 6s 19ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 633.1789 - regularization_loss: 0.0000e+00 - total_loss: 633.1789\n",
      "Epoch 3/5\n",
      "284/284 [==============================] - 6s 19ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 519.7366 - regularization_loss: 0.0000e+00 - total_loss: 519.7366\n",
      "Epoch 4/5\n",
      "284/284 [==============================] - 6s 19ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 493.7233 - regularization_loss: 0.0000e+00 - total_loss: 493.7233\n",
      "Epoch 5/5\n",
      "284/284 [==============================] - 6s 19ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 481.7788 - regularization_loss: 0.0000e+00 - total_loss: 481.7788\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2f52a7e50>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book2book_model.fit(train, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ISBN</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>book_0002005018</td>\n",
       "      <td>[0.24529923, 0.026332198, 0.10543761, 0.024581...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>book_0060973129</td>\n",
       "      <td>[0.15041944, -0.20085151, 0.01697667, -0.02865...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>book_0374157065</td>\n",
       "      <td>[0.22796887, 0.35494435, -0.09789037, 0.053342...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>book_0399135782</td>\n",
       "      <td>[0.3008597, 0.14158057, 0.008636907, 0.1293548...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>book_1558746218</td>\n",
       "      <td>[0.16193992, -0.110393316, -0.06777033, 0.0885...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              ISBN                                          embedding\n",
       "0  book_0002005018  [0.24529923, 0.026332198, 0.10543761, 0.024581...\n",
       "1  book_0060973129  [0.15041944, -0.20085151, 0.01697667, -0.02865...\n",
       "2  book_0374157065  [0.22796887, 0.35494435, -0.09789037, 0.053342...\n",
       "3  book_0399135782  [0.3008597, 0.14158057, 0.008636907, 0.1293548...\n",
       "4  book_1558746218  [0.16193992, -0.110393316, -0.06777033, 0.0885..."
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function to apply the model to each book feature set and return ISBN with embeddings\n",
    "def extract_embeddings_with_isbn(features):\n",
    "    embeddings = book2book_model.book_model(features)\n",
    "    return features['ISBN'], embeddings\n",
    "\n",
    "# Mapping the function over the dataset\n",
    "book_embeddings = book_infos.map(extract_embeddings_with_isbn)\n",
    "isbn_list = []\n",
    "embeddings_list = []\n",
    "\n",
    "# Example to inspect or use the embeddings with ISBNs\n",
    "for isbn, embedding in book_embeddings:\n",
    "    isbn_list.extend(list(isbn.numpy().astype(str)))  \n",
    "    embeddings_list.extend(list(embedding.numpy()))\n",
    "\n",
    "book_embedding_dataset = pd.DataFrame({'ISBN':isbn_list, 'embedding':embeddings_list})\n",
    "book_embedding_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_embedding_dict = dict(zip(book_embedding_dataset.ISBN, book_embedding_dataset.embedding))\n",
    "book_title_dict = dict(zip(books['ISBN'], books['Book-Title']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = output_dimension\n",
    "\n",
    "num_elements = book_embedding_dataset.shape[0]\n",
    "# hnswlib initialization with cosine similarity\n",
    "p = hnswlib.Index(space='cosine', dim=dim)\n",
    "\n",
    "p.init_index(max_elements=num_elements, ef_construction=100, M=16)\n",
    "\n",
    "p.set_ef(10)\n",
    "\n",
    "embeddings = np.vstack(book_embedding_dataset[\"embedding\"].values)\n",
    "p.add_items(embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similar Book Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def book_search(isbn, k=3):\n",
    "    \"\"\"Gets input embeddings and return top k similar items\"\"\"\n",
    "\n",
    "    # Generate embedding for the user query\n",
    "    query_embedding = book_embedding_dict[isbn]\n",
    "\n",
    "    if query_embedding is None:\n",
    "        return \"Invalid query or embedding generation failed.\"\n",
    "\n",
    "    labels, _ = p.knn_query(query_embedding, k=k+1)\n",
    "    results = book_embedding_dataset.iloc[list(labels[0][1:])].to_dict('records')\n",
    "    similar_isbns = [similar_isbn['ISBN'] for similar_isbn in results]\n",
    "    return similar_isbns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main Book:\n",
      "Harry Potter and the Sorcerer's Stone (Book 1)\n",
      "\n",
      "Similar Books:\n",
      "1. Harry Potter and the Sorcerer's Stone (Book 1 Audio CD)\n",
      "2. Harry Potter and the Prisoner of Azkaban (Book 3)\n",
      "3. Harry Potter and the Order of the Phoenix (Book 5)\n",
      "4. Sleeping Beauty: A Novel\n",
      "5. The Lovely Bones: A Novel\n",
      "6. Sacred\n",
      "7. The great fire\n",
      "8. BAG OF BONES : A NOVEL\n",
      "9. Casual Rex: A Novel\n",
      "10. Trouble Man the Life and Deat Gaye\n"
     ]
    }
   ],
   "source": [
    "# Visualization of Recommendation\n",
    "# ISBN of \"Harry Potter and the Sorcerer's Stone (Book 1)\"\n",
    "main_book = 'book_0590353403'\n",
    "print(f\"Main Book:\\n{book_title_dict[main_book]}\\n\\nSimilar Books:\")\n",
    "\n",
    "similar_books = book_search(main_book, k=10)\n",
    "for i, similar_book in enumerate(similar_books):\n",
    "    print(f\"{i+1}. {book_title_dict[similar_book]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommendations & Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top Products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Popular Books:\n",
      "1. Anne of Avonlea (Anne of Green Gables Novels (Paperback))\n",
      "2. El Codigo Da Vinci / The Da Vinci Code\n",
      "3. Maus 1. Mein Vater kotzt Geschichte aus. Die Geschichte eines ??berlebenden.\n",
      "4. Complete Chronicles of Narnia\n",
      "5. The Cat in the Hat\n",
      "6. The Ultimate Hitchhiker's Guide\n",
      "7. Dandelion Wine (Grand Master Editions)\n",
      "8. The Grapes of Wrath\n",
      "9. Der Alchimist.\n",
      "10. The Little Prince (Wordsworth Collection)\n"
     ]
    }
   ],
   "source": [
    "def get_popular_books(df_ratings, k=10):\n",
    "  # Calculate the number of ratings for each movie\n",
    "  rating_counts = df_ratings['ISBN'].value_counts().reset_index()\n",
    "  rating_counts.columns = ['ISBN', 'rating_count']\n",
    "\n",
    "  # Get the most frequently rated movies\n",
    "  min_ratings_threshold = rating_counts['rating_count'].quantile(0.95)\n",
    "\n",
    "  # Filter movies based on the minimum number of ratings\n",
    "  popular_movies = ratings.merge(rating_counts, on='ISBN')\n",
    "  popular_movies = popular_movies[popular_movies['rating_count'] >= min_ratings_threshold]\n",
    "\n",
    "  # Calculate the average rating for each movie\n",
    "  average_ratings = popular_movies.groupby('ISBN')['Book-Rating'].mean().reset_index()\n",
    "\n",
    "  # Get the top 10 rated movies\n",
    "  top_10_movies = list(average_ratings.sort_values('Book-Rating', ascending=False).head(k).ISBN.values)\n",
    "  return top_10_movies\n",
    "\n",
    "popular_books = get_popular_books(ratings)\n",
    "print(\"Popular Books:\")\n",
    "for i, popular_book in enumerate(popular_books):\n",
    "  print(f\"{i+1}. {book_title_dict[popular_book]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similar Products "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to apply the model to each book feature set and return ISBN with embeddings\n",
    "def extract_pairs(features):\n",
    "    return features['main_ISBN'], features['similar_ISBN']\n",
    "\n",
    "main_isbn_list = []\n",
    "similar_isbn_list = []\n",
    "\n",
    "book_pairs_test = test.map(extract_pairs)\n",
    "for main_isbn, similar_isbn in book_pairs_test:\n",
    "    main_isbn_list.extend(list(main_isbn.numpy().astype(str)))  \n",
    "    similar_isbn_list.extend(list(similar_isbn.numpy().astype(str)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "popular_reco_results = []\n",
    "two_tower_reco_results = []\n",
    "k = 50\n",
    "popular_books = get_popular_books(ratings, k=k)\n",
    "\n",
    "for main_isbn, similar_isbn in zip(main_isbn_list, similar_isbn_list):\n",
    "    popular_reco_check = np.isin(popular_books, similar_isbn).astype(int)\n",
    "    popular_reco_results.append(popular_reco_check)\n",
    "    # get embedding based recommendations\n",
    "    similar_books = book_search(main_isbn, k=k)\n",
    "    two_tower_check = np.isin(similar_books, similar_isbn).astype(int)\n",
    "    two_tower_reco_results.append(two_tower_check)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NDCG Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Two Tower NDCG result at top 10: 0.0112\n",
      "Popular recommendation NDCG result at top 10: 0.0\n",
      "\n",
      "\n",
      "Two Tower NDCG result at top 20: 0.012\n",
      "Popular recommendation NDCG result at top 20: 0.0\n",
      "\n",
      "\n",
      "Two Tower NDCG result at top 50: 0.0135\n",
      "Popular recommendation NDCG result at top 50: 0.0014\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import ndcg_score\n",
    "\n",
    "# Since we have already sorted our recommendations\n",
    "# An array that represent our recommendation scores is used.\n",
    "representative_array = [[i for i in range(k, 0, -1)]] * len(two_tower_reco_results)\n",
    "\n",
    "for k in [10, 20, 50]:\n",
    "  two_tower_result = ndcg_score(two_tower_reco_results,\n",
    "                                  representative_array, k=k)\n",
    "  popular_result = ndcg_score(popular_reco_results,\n",
    "                              representative_array, k=k)\n",
    "  \n",
    "  print(f\"Two Tower NDCG result at top {k}: {round(two_tower_result, 4)}\")\n",
    "  print(f\"Popular recommendation NDCG result at top {k}: {round(popular_result, 4)}\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "- https://www.tensorflow.org/recommenders/examples/basic_retrieval\n",
    "- https://www.tensorflow.org/recommenders/examples/featurization"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "feast",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
